\begin{abstract}
Our project involves refining noisy structured knowledge bases in a scalable, distributed manner.
We focus on NELL, the Never Ending Language Learner, which extracts information
from the Web and compiles it into a belief ontology.
We will leverage GraphLab's, parallel belief propagation algorithm
to correct the uncertainty in NELL's knowledge base.
In doing so, we hope to provide a distributed solution to such noise-correction tasks
that performs more scalably and efficiently than current solutions.
\end{abstract}
